{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3689ebf0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#what is perceptron \n",
    "#logistic regression \n",
    "#applied for problem where it is not linearly seprable \n",
    "a1x1+b1x2+c=0\n",
    "a1,b1.c change then line will also change in orientation \n",
    "w1x1+w2x2+w3=0\n",
    "\n",
    "\n",
    "epoc 100 try to find best w1,w2,w3  is algo intends...\n",
    "wnew=w_old-learning_rate*x_feature  when wx>=0\n",
    "w_new =w_old+learning_rate*x_feature  when wx<0 \n",
    "just trying to formulate a bell curve , normalised curve , a convex function , where i can ge minima , n i can able to find differenciation , slope for curve \n",
    "what is learning rate ? why is used ?\n",
    "what is optimal value how to decide val of learning rate ?\n",
    "A high learning rate can cause the model to converge too quickly possibly skipping over the optimal solution.\n",
    "A low learning rate might lead to slower convergence and require more time and computational resources.\n",
    "\n",
    "epocs \n",
    "what are hyperparameter ?learn rate , epochs , activation func \n",
    ">>>>control leraning process rate \n",
    "\n",
    "hyperparameter tuning ? GridCV\n",
    "accuracy check techniques ?\n",
    "sigmoid activation function ?\n",
    "convex func vs concave func ?global minima ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70899fe9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    select a random student ith \n",
    "    w_new=w_old+learn_rate(y-y_hat)*feature_x_i #this is for feature 1 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b4c7f1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def perceptron(X,y):\n",
    "    \n",
    "    X = np.insert(X,0,1,axis=1)\n",
    "    weights = np.ones(X.shape[1])\n",
    "    lr = 0.1\n",
    "    \n",
    "    for i in range(1000):\n",
    "        j = np.random.randint(0,100)\n",
    "        y_hat = step(np.dot(X[j],weights))\n",
    "        weights = weights + lr*(y[j]-y_hat)*X[j]\n",
    "        \n",
    "    return weights[0],weights[1:]\n",
    "\n",
    "\n",
    "\n",
    "def step(z):\n",
    "    return 1 if z>0 else 0    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfe4042",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lor = LogisticRegression()\n",
    "lor.fit(X,y)\n",
    "\n",
    "lor.predict(X_test)\n",
    "#prediction value :0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e898284",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "m = -(lor.coef_[0][0]/lor.coef_[0][1])\n",
    "b = -(lor.intercept_/lor.coef_[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307f1b6e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model, metrics\n",
    "print(f\"Logistic Regression model accuracy: {metrics.accuracy_score(y_test, y_pred) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e2524a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#accuracy , precision , recall , f1 score "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
